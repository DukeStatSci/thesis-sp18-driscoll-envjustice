---
author: 'Anne Driscoll'
date: 'May 2018'
institution: 'Duke University'
division: 'Trinity College of Arts and Sciences'
advisor: 'David Banks'
#altadvisor: 'Your Other Advisor'
# Delete line 7 if you only have one advisor
committeememberone: 'Committeemember O. Name'
committeemembertwo: 'Committeemember T. Name'
dus: 'Mine Cetinkaya Rundel'
department: 'Department of Statistical Science'
degree: 'Bachelor of Science in Statistical Science'
title: 'Examining Injustice in Environmental Toxicity'
knit: "bookdown::render_book"
site: bookdown::bookdown_site
output: 
#  thesisdowndss::thesis_pdf: default
  thesisdowndss::thesis_gitbook: default
#  thesisdowndss::thesis_word: default
#  thesisdowndss::thesis_epub: default
# If you are creating a PDF you'll need to write your preliminary content here or
# use code similar to line 20 for the files.  If you are producing in a different
# format than PDF, you can delete or ignore lines 20-31 in this YAML header.
abstract: |
  `r if(knitr:::is_latex_output()) paste(readLines("00-abstract.Rmd"), collapse = '\n  ')`
# If you'd rather include the preliminary content in files instead of inline
# like below, use a command like that for the abstract above.  Note that a tab is 
# needed on the line after the |.
acknowledgements: |
  I want to thank a few people.
dedication: |
  You can have a dedication here if you wish. 
preface: |
  This is an example of a thesis setup to use the reed thesis document class
  (for LaTeX) and the R bookdown package, in general.
bibliography: bib/thesis.bib
# Refer to your specific bibliography file in the line above.
csl: csl/apa.csl
# Download your specific csl file and refer to it in the line above.
lot: true
lof: true
space_between_paragraphs: true
# Delete the # at the beginning of the previous line if you'd like
# to have a blank new line between each paragraph
#header-includes:
#- \usepackage{tikz}
---

<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Dedication, for example, simply delete lines 17 and 18 above or add a # before them to comment them out.  If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this.
-->

<!--
If you receive a duplicate label error after knitting, make sure to delete the index.Rmd file and then knit again.
-->

```{r libraries, include_packages, include = FALSE}
library(knitr)
knitr::opts_chunk$set(fig.width=10, fig.height=4, echo = FALSE) 
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)

if(!require(devtools))
  install.packages("devtools", repos = "http://cran.rstudio.com")
if(!require(thesisdowndss))
  devtools::install_github("mine-cetinkaya-rundel/thesisdowndss")
library(thesisdowndss)
if(!require(rseiAnalysis)){
  devtools::install_github("amd112/rseiAnalysis")
  library("rseiAnalysis")
}

library(magrittr)
library(readr)
library(ggplot2)
library(dplyr)
library(plyr)
#library(zoo)
library(lemon)
library(stringr)
library(spatstat)
library(quantreg)
library(readr)
library(tidyr)
library(lme4)
library(devtools)
library(data.table)
library(grid)
library(gridExtra)

#needed for RSEI
set.seed(4012)
```

```{r readInData, include = FALSE}
t1990 = as.data.frame(fread("data/toxic/tract/toxic_1990_2010_tract.csv", data.table = FALSE))
t1991 = as.data.frame(fread("data/toxic/tract/toxic_1991_2010_tract.csv", data.table = FALSE))
t1992 = as.data.frame(fread("data/toxic/tract/toxic_1992_2010_tract.csv", data.table = FALSE))
t1993 = as.data.frame(fread("data/toxic/tract/toxic_1993_2010_tract.csv", data.table = FALSE))
t1994 = as.data.frame(fread("data/toxic/tract/toxic_1994_2010_tract.csv", data.table = FALSE))
#t1995 = as.data.frame(fread("data/toxic/tract/toxic_1995_2010_tract.csv", data.table = FALSE))
t1996 = as.data.frame(fread("data/toxic/tract/toxic_1996_2010_tract.csv", data.table = FALSE))
t1997 = as.data.frame(fread("data/toxic/tract/toxic_1997_2010_tract.csv", data.table = FALSE))
t1998 = as.data.frame(fread("data/toxic/tract/toxic_1998_2010_tract.csv", data.table = FALSE))
t1999 = as.data.frame(fread("data/toxic/tract/toxic_1999_2010_tract.csv", data.table = FALSE))
t2000 = as.data.frame(fread("data/toxic/tract/toxic_2000_2010_tract.csv", data.table = FALSE))
t2001 = as.data.frame(fread("data/toxic/tract/toxic_2001_2010_tract.csv", data.table = FALSE))
t2002 = as.data.frame(fread("data/toxic/tract/toxic_2002_2010_tract.csv", data.table = FALSE))
t2003 = as.data.frame(fread("data/toxic/tract/toxic_2003_2010_tract.csv", data.table = FALSE))
#t2004 = as.data.frame(fread("data/toxic/tract/toxic_2004_2010_tract.csv", data.table = FALSE))
t2005 = as.data.frame(fread("data/toxic/tract/toxic_2005_2010_tract.csv", data.table = FALSE))
t2006 = as.data.frame(fread("data/toxic/tract/toxic_2006_2010_tract.csv", data.table = FALSE))
t2007 = as.data.frame(fread("data/toxic/tract/toxic_2007_2010_tract.csv", data.table = FALSE))
t2008 = as.data.frame(fread("data/toxic/tract/toxic_2008_2010_tract.csv", data.table = FALSE))
t2009 = as.data.frame(fread("data/toxic/tract/toxic_2009_2010_tract.csv", data.table = FALSE))
t2010 = as.data.frame(fread("data/toxic/tract/toxic_2010_2010_tract.csv", data.table = FALSE))
t2011 = as.data.frame(fread("data/toxic/tract/toxic_2011_2010_tract.csv", data.table = FALSE))
t2012 = as.data.frame(fread("data/toxic/tract/toxic_2012_2010_tract.csv", data.table = FALSE))
t2013 = as.data.frame(fread("data/toxic/tract/toxic_2013_2010_tract.csv", data.table = FALSE))
t2014 = as.data.frame(fread("data/toxic/tract/toxic_2014_2010_tract.csv", data.table = FALSE))

read_in_pov = function(year, tox) {
  data = as.data.frame(fread(paste0("data/census/income_tract_", year, ".csv"), data.table = FALSE))
  data = data[complete.cases(data), ]
  data$id = str_pad(data$id, 11, pad = "0", side = "left")
  data = merge(data, tox, by.x = "id", by.y = "block")
  data$year = year
  return(data)
}

p1990 = read_in_pov(1990, t1990)
p1991 = read_in_pov(1991, t1991)
p1992 = read_in_pov(1992, t1992)
p1993 = read_in_pov(1993, t1993)
p1994 = read_in_pov(1994, t1994)
p1996 = read_in_pov(1996, t1996)
#p1995 = read_in_pov(1995, t1995)
p1997 = read_in_pov(1997, t1997)
p1998 = read_in_pov(1998, t1998)
p1999 = read_in_pov(1999, t1999)
p2000 = read_in_pov(2000, t2000)
p2001 = read_in_pov(2001, t2001)
p2002 = read_in_pov(2002, t2002)
p2003 = read_in_pov(2003, t2003)
#p2004 = read_in_pov(2004, t2004)
p2005 = read_in_pov(2005, t2005)
p2006 = read_in_pov(2006, t2006)
p2007 = read_in_pov(2007, t2007)
p2008 = read_in_pov(2008, t2008)
p2009 = read_in_pov(2009, t2009)
p2010 = read_in_pov(2010, t2010)
#p2011 = read_in_pov(2011, t2011)
#p2012 = read_in_pov(2012, t2012)
#p2013 = read_in_pov(2013, t2013)

pov_data = rbind.fill(p1990, p1991, p1992, p1993, p1994, p1996, p1997, p1998, p1999, p2000, p2001, p2002, p2003, p2005, p2006, p2007, p2008, p2009, p2010)

#Environmental justice literature has focused largely on the motivations behind facility siting that lead to inequality and policy approaches to help fix the disproportionate burden of environmental hazards on minority communities. The questions being asked are critical to creating policy that helps correct the problem of hazard allocation. A gap in the literature is the need for an investigation of the dynamic world of hazard allocation over time. 

# what is natural sorting, How are env dumps created?, Breaking the self fulfilling cycle

read_in = function(year, tox) {
  data = as.data.frame(fread(paste0("data/census/hisp/hisp_tract_", year, ".csv"), data.table = FALSE))
  data = data[complete.cases(data), ]
  data$other_sum = rowSums(data[, 5:7])
  data = select(data, id, pop, white, black, hispanic, other_sum)
  names(data) = c("id", "pop", "white", "black", "hispanic", "other")
  data$id = str_pad(data$id, 11, pad = "0", side = "left")
  data = merge(data, tox, by.x = "id", by.y = "block")
  data$year = year
  return(data)
}

h1990 = read_in(1990, t1990)
h1991 = read_in(1991, t1991)
h1992 = read_in(1992, t1992)
h1993 = read_in(1993, t1993)
h1994 = read_in(1994, t1994)
#h1995 = read_in(1995, t1995)
h1996 = read_in(1996, t1996)
h1997 = read_in(1997, t1997)
h1998 = read_in(1998, t1998)
h1999 = read_in(1999, t1999)
h2000 = read_in(2000, t2000)
h2001 = read_in(2001, t2001)
h2002 = read_in(2002, t2002)
h2003 = read_in(2003, t2003)
#h2004 = read_in(2004, t2004)
h2005 = read_in(2005, t2005)
h2006 = read_in(2006, t2006)
h2007 = read_in(2007, t2007)
h2008 = read_in(2008, t2008)
h2009 = read_in(2009, t2009)
h2010 = read_in(2010, t2010)
h2011 = read_in(2011, t2011)
h2012 = read_in(2012, t2012)
h2013 = read_in(2013, t2013)

hisp_data = rbind.fill(h1990, h1991, h1992, h1993, h1994, h1996, h1997, h1998, h1999, h2000, h2001, h2002, h2003, h2005, h2006, h2007, h2008, h2009, h2010, h2011, h2012, h2013)

msa_tracts = fread("data/census/msa_tracts.csv", data.table = FALSE)[, 1]

data = merge(hisp_data, pov_data, by = c("id", "year"), all.x = TRUE)
data = data[, 1:18]
names(data)[8:9] = c("concentration", "area")
data$density = data$pop/data$area
data$pov_pop = rowSums(data[, 10:18])

msa_data = data[data$id %in% msa_tracts, ]
dense_data = data[data$density > as.numeric(data$density)[5], ]
```


<!-- You'll need to include the order that you'd like Rmd files to appear in the _bookdown.yml file for
PDF files and also delete the # before rmd_files: there.  You'll want to not include 00(two-hyphens)prelim.Rmd
and 00-abstract.Rmd since they are handled in the YAML above differently for the PDF version.
-->

<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers
on chapters.
-->

# Abstract {.unnumbered}

Environmental justice studies have been significantly limited by data availability, focusing on neighborhood level studies and working hand in hand with organizers to study toxicity disparity patterns within communities. As an injustice inherent to the societal structure of our nation, environmental justice questions should be addressed at a national scale. The Risk Screening Environmental Indicator model (RSEI) data was released for public use in 2015, allowing work with fine-grained toxicity data available nationally since 1988. 

RSEI data is fine-grained dataset, reporting toxicity on an 800m by 800m grid across the US. However RSEI contains many inconsistencies over time, and needs to be aggregated to the census geography. By aggregating RSEI data, we are able to calculate toxicity measures for each block group. In combination with the census data, this allows us to estimate distributions of toxicity experienced by minority groups in the United States. Additionally, we are able to analyze macro level trends over time, such as the overall geography of toxicity in the United States, how the 5^th^, 50^th^, and 95^th^ percentiles of toxicity experienced by each race group varies over time, and how income brackets relate to toxicity experienced for each race group. 

Results show that toxicity is decreasing dramatically for all and, though the gap is closing, there still remains a large difference in toxicity experienced between white and minority groups. Additionally, the effects of income on experienced toxicity are unclear, and may need additional data to untangle.

In order to make results accessible, they are incorporated into a publicly available app that allows users to investigate toxicity in their area relative to the U.S. at large, and investigate the differences in local race-related toxicity burden. Additionally, a package containing functions to help convert RSEI dissaggregated microdata to a consistent form was created to help make the work reproducible and encourage work on similar questions.


### Keywords {.unnumbered}
Environmental Inequality, Racial Inequality, Public Use, Simulation, Toxicity, Temporal Analysis

<!--chapter:end:index.Rmd-->

# Theoretical Background {#env_justice}

The growing body of environmental literature strives to investigate how minorities differently experience pollution as compared to the white population. The literature has focused primarily on air pollution and industrial facilities releases in America, the areas with the most consistently accessible data. Many authors have focused on point source pollution, measuring how individuals experience pollution as a binary: the presence or absence of a polluting facility in the geographic unit of analysis (Szasz and Meuser, 1997). An alternate measure of pollution exposure is the count of polluting facilities within increasingly large buffer zones. These measures, limited by available data, fail to account for the variance in what chemicals, and how much of them, facilities emit. Alternate approaches have included data on transportation emissions and  levels of NO~2~ and PM~2.5~ measured by air quality monitors. 

The conclusions of environmental justice literature are not unanimous. Many studies conclude that minorities do experience a disproportionate toxicity or pollution burden (Gilbert and Chakraborty, 2011; Fisher, Kelly and Romm, 2006; Kravitz-Wirtz et al., 2016), others find that economic class accounts for most of the difference in experienced toxicity (Anderton et al., 1994), yet others find no significant differences at all (Hunter et al., 2003; Downey, 2007). The incredibly heterogeneous results have led to some dissent, with some arguing that all the field has achieved is to show that "in **some** specific areas, **some** ostensibly identifiable groups **may**, in **some** instances, live closer to **some selected** environmental hazards" (Bowen, 2002, emphasis added).

These discordant results are likely rooted in the past availability of data in environmental justice research and the field's relationship with advocacy. Environmental justice research is unique in that research and advocacy have gone hand in hand, leading to research guided by the needs of communities. This has led to an unusually focused body of work, evaluating specific communities for the presence of specific toxins at specific times (Sadd et al., 1999; US GAO, 1893; Moghadam and Kayahan, 2017; Gilbert and Chakraborty, 2011). Though some work has had a broader net, few authors have broached national data (Ringquist, 1997; Hunter et al., 2003) and even fewer have used data spanning significant time (Kravitz-Wirtz et al., 2016). Due to the definitions of pollution used, uncertainty in pollution data, and differing geographic units of analysis, work spanning broader time periods and geographic regions is necessary to show the existence of environmental inequality on a national scale and begin to understand the processes that lead to environmental inequality.

Despite differing conclusions from the collective body of research, how we define and think about environmental justice is evolving. Several theories of how environmental injustices are created have arisen. The main theories on the origin of environmental injustice are economic, sociopolitical, and discriminatory explanations. What follows is an overview of past environmental justice research and theory, computational background is included in Chapter 5.

## Economic Explanations

Theories focusing on economic aspects of environmental inequality rely on individual and industrial rational choice as an explanation. In the case of facility point source pollution, companies must make economically rational decisions when siting facilities. Those decisions can be multifaceted: if the location has easy access to transportation, or is close to raw materials, but a primary concern is cost of land. Given companies prefer siting polluting facilities on cheap land, and minority communities are frequently near cheap land (Anderton et al., 1994), it's rational that there would be more facility siting in minority areas. 

In the same vein, it would be economically rational for those with the means to escape newly sited pollution to do so (Hunter et al., 2003). Under this theory, cheaper land is more likely to be near minority communities, facilities will be sited there, and those who can afford to escape do so, devaluing the land further, and making it all the more attractive for facility siting. This would create a spiral that results in areas that act as wells for toxicity. Results have been mixed: several studies found that more facilities were sited in minority communities (Crowder and Downey, 2010), while others didn't (Pais et al., 2013). 

## Sociopolitical Explanations

Sociopolitical explanations also rely upon siting decisions, but are more explicitly exploitative. Sociopolitical explanations theorize that companies choose to site in minority communities, as at risk communities will provide less resistance. At risk communities could be communities that  show a lower voter turnout, have a large older population, are disproportionately renters, or are poorly politically represented. In theory, communities with lower organizing potential are more attractive for facility siting, as they pose a low risk of creating political or economic resistance to the proposed facility. 

## Racial Discrimination

Racial discrimination theories are divided in to overt and institutional racism theories. In discussion of these theories the language used tends to change, using the term 'environmental racism' rather than 'environmental justice'. 

The overt discrimination theory speculates that siting decisions are made to intentionally cause strife to minority communities or to protect wealthy white communities. 

The institutional discrimination theory operates primarily on housing dynamics. Based on the knowledge that the number of minority individuals living near a sited facility has risen since first measured (Crowder et al., 2010), the theory states that minorities move towards polluting facilities due to reduced choice in the housing market. Reduced choice can arise in the choices realtors make in showing homes or the availability of mortgages. Local governments can compound problems with housing, as minority areas are more likely to be rezoned for industrial purposes by local government (Pais et al., 2013). 


These three theories all point to the same outcome. Despite using different language and explanations, all represent different forms of institutional discrimination. Economic explanations rely on the segregation of minority communities created by redlining. Redlining destroyed investment in communities, prevented black families from investing in homes, and enforced segregated communities. Redlining created the geography and culture that enables economic and sociopolitical explanation, making it a consequence of previous overt discrimination. 

<!--chapter:end:01-env_justice.Rmd-->

# Goals {#goals}

This work aims to address some of the limitations of the current environmental justice literature by examining a comprehensive data set that covers the entire nation, with data spanning from 1988 to 2015. The broad temporal and spatial coverage is nearly unparalleled in environmental justice literature, with the last study of this length spanning the years 1970 to 1994 (Been and Gupta, 1997), relying solely upon tract level hazardous waste site data. 

The goals of this paper are:

* To build empirical distributions of toxicity experienced by the American public. Using those distributions to find empirical 5^th^, 50^th^, and 95^th^ percentiles of experienced toxicity for white, black, and Hispanic populations over time. Rather than examining the mean of each group, these percentiles give us an idea of which groups have access to areas with low toxicity, which groups are most at risk for extreme toxicity (which is most likely to relate to lifestyle or health effects,) and an idea of how the median changes for each group. 

* Simulating how minority distributions would look in 2015 given they had held constant their relative position in the overall distribution of 1990. This measure allows us to see how much of the improvement in relative toxicity is attributable to the compression of the overall toxicity distribution, and how much is attributable to changes in the relative state of minority groups. 

* To create a web app that provides a searchable map database with information on local toxicity, and the local state of environmental justice. The goal of this app is to make complex data accessible for public use. Additionally, to create a package containing functions that help convert RSEI dissaggregated microdata to a consistent Census compatible form, in order to make the base data more accessible. 

<!--chapter:end:02-goals.Rmd-->

# Data {#data}

## Risk Screening Environmental Indicators Model Data

The Risk Screening Environmental Indicators (RSEI) Model is a geographically detailed data set produced by the United States Environmental Protection Agency (EPA). RSEI data is based upon the Toxic Release Inventory (TRI), a data set on toxic releases in the United States. 

TRI data is self reported by facilities, with each observation being a release of a reporting chemical at a reporting facility. For each observation, data is collected on which chemical was released, how much of it was released, and the facility from which it was released. This data is collected for a mandated list of industries, facilities, and chemicals that change over time. For a release to be reported it has to be a mandated chemical, released by a mandated facility in a mandated industry.

The detailed location and chemical data that is collected through TRI is reformatted through a fate and transport model to create RSEI. The RSEI data shows where each release has traveled, from its initial point of release, on an 800m by 800m grid across the USA. The ultimate data is an observation for each release, for each square in the grid that the release hits. This gives us an idea of how the chemicals spread from the source locations, and enables us to create a map across the entire nation for where TRI chemicals accumulate in any year between 1988 and 2014. This is a much improved measure of pollution, as it theoretically shows the amount of toxins experienced in any given location.

The initial RSEI disaggregated microdata is approximately 4 terabytes of data. Given that the 800m by 800m grid across the United States has on the order of 10 million squares, each release hits many squares, we have many releases, and the data covers 24 years, this is an enormous data set.

The RSEI reformat of the TRI contains the following variables: X and Y are the geographic identifiers for the cell on the grid across the US, with (0, 0) in the center of the US. Release number tells us which release that row is associated with. Chemical number through media are all release specific data. Conc (concentration) is specific to the release at that square, indicating the concentration of the chemical across that grid cell. ToxConc is the toxicity weighted concentration of that release in that grid cell. 'Score' variables are toxicity values as weighted by the population in that grid cell. 

Below see an example of the disaggregated microdata:

|X   |Y   |Release|Chem|Facility|Media|Conc  |ToxConc|Score|
|----|----|-------|----|--------|-----|------|-------|-----|
|-185|51  |2050156|317 |3       |1    |4.6e-4|2.28e-3|0    |
|-184|41  |2050156|317 |3       |1    |3.3e-4|1.65e-3|0    |
|-184|42  |2050156|317 |3       |1    |3.3e-4|1.67e-3|0    |
|-184|43  |2050156|317 |3       |1    |3.3e-4|1.66e-3|0    |
|-184|44  |2050156|317 |3       |1    |3.4e-4|1.68e-3|0    |
|... |... |...    |... |...     |...  |...   |...    |...  |



## Important Caveats

Due to the nature of the data, there are a few interesting caveats to consider. 

The RSEI data is self reported, and has been thought to contain some severe under reporting (De Marchi and Hamilton, 2006). This could lead to low estimates of toxicity, and could bias results if certain areas or industries are more likely to under report. Highly regulated chemicals may be more likely to be under reported, as facilities are incentivized to release as little as possible.

The data is entirely based off a black box fate and transport model. The model has uncertainty that is not reported in RSEI and therefore is not being addressed. The raw data we use are estimates to begin with, but are being treated as observed data. 

The data only captures releases for certain facility types within certain industries, for certain chemical types within those facilities. Not all chemicals are mandated reporting, and any analysis that is done based off the data can't be extrapolated to discuss toxicity more generally. Some important industries (like mining) are not monitored over the entire period, and are removed to ensure consistency over time, so areas that strongly represent those industries will have deflated toxicity estimates. 

Because RSEI only captures a specific subset of chemicals, it is difficult to relate the RSEI scores to health or quality of life outcomes in an area. There are many obvious environmental hazards that are likely to have strong influence on public health and living conditions that TRI doesn't address, eg: brownfields, solid waste disposal, animal farming, hazardous waste, etc.

Another detail of the data that makes interpreting results difficult is how chemicals are compared. RSEI gives the weight of the release and the chemical of the release, but chemicals have very different levels of toxicity. A small amount of mercury released is much worse than a small amount of CO2. To that end, the EPA assigned each chemical a 'toxicity' weight, by which the amount of the chemical released is multiplied. This means that we can aggregate all the chemicals in an area, and compare the overall toxicity over space and time. The toxicity weights allow us to compare to other chemicals' toxicity weight, and overall toxicity of a given chemical release, but also means that the values only have meaning in comparison.

Despite the limitations that the data presents, it provides an incredibly detailed and complex view of toxicity in the United States that is worth delving in to. 

## Data Continuity

### Census Comparability

RSEI data is available between 1988 and 2015, and over that time Census geographies have experienced considerable overhaul. Many of our questions of interest involve demographic characteristics, and the changes we see in environmental toxicity over time for those demographics. As such, we need aggregate toxicity to block group or tract level in order to merge with Census data. To do so, we calculate the toxicity values in Census 2010 geography. Since we want to use Census areas as the unit of analysis, we use crosswalks that help us transform past Census data to the 2010 geographies. 

### Chemical Consistency

Consistency across time, space, and chemicals is vital in order to be able to compare toxicity values across time. Though the EPA is incredibly detailed in their data collection, they are also subject to changing scientific consensus and legislation, and therefore haven't been able to provide entirely consistent data. 

Over time, as chemicals have been found to be toxic, they have been added to the list of TRI mandated reporting chemicals. There are also chemicals that have been removed from the mandated reporting list. Because the list of chemicals reported changes over time, aggregating all the data would cause us to see artificial jumps in toxicity. These jumps wouldn't be reflective of actual increases in toxicity, but rather toxicity that was beginning to be measured. These jumps may change what areas appear toxic in the data, as industries that don't have to report at some point in the time frame will be entirely removed from the data set. Several of those industries are very highly polluting, and after elimination locations that focus strongly on those industries will show deflated scores. 

### Industry Reporting Consistency

TRI regulates who needs to self report using the North American Industry Classification System (NAICS), and before NAICS was available used its predecessor, the Standard Industrial Classification (SIC) system. Just as we see changes in the regulations for chemicals, we see changes in the regulations of various industries. NAICS codes that need to report are regulated independently of chemical codes, and NAICS codes that are not consistently reported across the time period of interest must be removed to maintain continuity. 

As an example, a textiles facility releasing mercury might fall under mandated reporting due to their NAICS code, but the neighboring mining facility that also releases mercury might not have to report because of the NAICS code. If that changes over the time period, and suddenly the mining industry also mandates reporting, we will see an artificial huge jump in the mercury present in that area if we don't remove by industry.

## Data Cleanup

Data cleaning was done with R using the DBI and SQLite packages (R-SIG-DB et al., 2018; Müller et al., 2018.). Since there is so much data, it's not feasible to process it using typical R functions, so we used a SQL database. This significantly speeds up the processes detailed below.

The disaggregated microdata from RSEI is one observation per release per cell on the 800m by 800m grid that it reached. We filter each of the observations to check that it is 

* from a chemical that is consistent across the relevant years, and

* from a release that is linked to an industry that is consistent across years,

then allocate the observation to the appropriate Census geographic unit. 

Filtering out observations whose releases are not under a regulated NAICS category for the entire time is complex. Using a table that contains the regulation and deregulation dates of NAICS codes we can find the consistent industry categories. However, the only reference to NAICS or SIC codes in RSEI data are not release specific. The Facility table provides the 6 NAICS codes most commonly associated with the facility. However, NAICS codes are release specific, not facility specific, meaning that for each emission reported a NAICS code is reported. Removing by facility will not yield accurate results, since facilities may have different types of NAICS emissions. The textiles facility we used as an example earlier might make both shoes and jackets. These production outputs would have different NAICS codes, meaning only releases originating from one production line would have to be reported. To get data on the NAICS codes by submission, we use the original TRI reporting form data, linking to RSEI disaggregated microdata by the document control number.

In the data cleansing process, we filter the data to remove industries and chemicals that were not consistent over the period of inquiry, and aggregate the data to the relevant Census geographies. The data then forms a data set for each year, with an observation for each block group, and just one measure, an aggregated toxicity level. 

|block        |concentration|area    |
|-------------|-------------|--------|
|010010201001	|627.3050138	|6.520168|
|010010201002	|499.6297799	|8.48669 |
|010010202001	|578.8311689	|3.137173|
|010010202002	|756.3733114	|1.962949|
|010010203001	|637.7356488	|5.907125|
|...          |...          |...     |


It's important to keep in mind throughout this discussion that the 'concentration' estimate must be interpreted in the context of the consistency adjustments. The pollution estimates are comparable across time and location, but only in the context of continuous EPA regulation, and can not be interpreted independently of one another.

<!--chapter:end:03-data.Rmd-->

# Exploratory Analysis {#trends}

## Toxicity Trends

Spurred by fear created by a disaster release of toxic chemicals in India, the Community Right to Know Act was created in 1986 to enforce reporting on hazardous chemicals being released in to the environment by individual facilities. [CITATION] TRI data, beginning in 1988, is the public release of the data created through the Community Right to Know Act.

The time after TRI began collection included a lot of environmental regulation, including the Montreal Protocol, the Clean Air Act Amendments of 1990, the Oil Pollution Act of 1990 and the 1994 Executive Order directing 'federal agencies to identify and address the disproportionately high ... environmental effects ... on minority populations.' (Executive Order, 1994) As environmental protections such as the mandated phase outs of CFC's and requirements for facilities to switch to Best Available Control Technology went in to place, collective environmental attitudes became greener. These trends lead us to expect large drops in toxicity for all groups over this time period. 


```{r alltoxicity, echo = FALSE, fig.width=7, fig.height=4}
pounds = fread("data/release_trends.csv", data.table = FALSE)[1:26, ]


ggplot(pounds) + geom_line(aes(x = as.double(year), y = as.double(tox))) + 
#  scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
#                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
#  annotation_logticks(short = unit(1,"mm"), mid = unit(2.2,"mm"), long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  labs(x = "Year", y = "Pounds of TRI Chemicals Released", title = "TRI releases by weight over time") +
  theme(plot.title = element_text(hjust = 0.5))
```

Looking at the net volume of TRI releases, we see a fairly linear drop in the pounds of TRI chemicals being released nationally between 1988 and 2013. Despite the common use of volume of TRI releases as a study measure (Szasz and Meuser, 1997) the rest of this work proceeds to use TRI toxicity as the measure of interest. TRI toxicity refers to the weight of each release multiplied by the toxicity weight assigned to the chemical by the EPA. Given that TRI chemicals vary significantly in their potential human effects, toxicity experienced is a better measure of the potential human impact than the net weight of toxic chemicals experienced. Toxicity is especially important in environmental justice work, as there is potential that more toxic releases are focused in minority communities, which would not be evident by net weight.

Toxicity trends look very different than the net release trends shown above. This is partially attributable to the strongly skewed distribution of toxicity. As some releases are of extremely toxic chemicals, the distribution of toxicities experienced is extremely right skewed by toxic dumps. 

```{r, echo = FALSE, fig.width=7, fig.height=4}
nonlog = ggplot(data[data$year == 2000,]) + geom_density(aes(concentration, weight = pop/sum(pop)), fill = "pink", color = "pink", alpha = 0.7) +
  labs(x = "Raw Toxicity", y = "Density", title = "Toxicities experienced in 2000") +
  theme(plot.title = element_text(hjust = 0.5))

log = ggplot(data[data$year == 2000,]) + geom_density(aes(concentration, weight = pop/sum(pop)), fill = "pink", color = "pink", alpha = 0.6) +
  labs(x = "Log Toxicity", y = "Density", title = "Log Toxicities experienced in 2000") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_x_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(1,"mm"), mid = unit(2.2,"mm"), long = unit(3.5,"mm"), sides = "b", color = "gray65")


grid.arrange(arrangeGrob(nonlog, log, nrow=1))
```

Given the extremely right skewed nature of this distribution, for ease of analysis and interpretation, from here on toxicity is reported as log toxicity. The distributions of log toxicity are much more interpretable, but care must be used to contextualize the results. 

In this application, there are locations that are orders of magnitude more toxic than the bulk of the United States. These are sites to be aware of, where toxicity is more likely to have an effect on people's lives or health. However, as discussed in the data section, toxicity measures don't necessarily align with the locations that we know are truly hazardous. 

Many of the locations that arise as especially toxic in the data are assuredly so. High Point, NC is consistently one of the most toxic tracts in the early 2000's, as confirmed by [EPA reports](https://cfpub.epa.gov/si/si_public_record_Report.cfm?dirEntryID=45198) identifying it as a location prime for testing toxicity abatement measures. Tracts outside of Salt Lake City commonly known for acting as [dumping grounds](http://www.nytimes.com/2002/10/20/us/utah-county-s-toxic-tradition-is-under-threat.html) are consistently ranked as toxic in the early 2000's. Mobile, AL, whose [3 superfund sites](https://19january2017snapshot.epa.gov/enforcement/case-summary-epa-funded-sites-and-communities-chemtura-bankruptcy-settlements_.html#stauffer) were proposed in the early 1990's, routinely ranks as toxic over that time period. 

On the contrary, there are many famous toxic events and locations that fail to ever reach the top 5% of toxic tracts, eg. Flint, MI, and the Houston major superfund site.

## Geography of Toxicity Trends

Toxic exposure has been changing dramatically in the US, but the trends it follows have remained similar. In the gif below, we show toxicity across the US from 2010 to 2014. 

![](https://raw.githubusercontent.com/DukeStatSci/thesis-sp18-driscoll-envjustice/master/index/figure/usa.gif)

Though we see impressive reductions over that time, the overall geographic trends of toxicity remain constant. Each region maintains its overall toxicity range, and toxicity wells appear to stay fairly constant. Given the infrastructure required to build up manufacturing, a large part of TRI, the consistency across time is expected. 

The toxicity wells we see in the image are familiar, as many of them occur around large cities, where there is likely to be industry. Though many large cities stand out as having high toxicity, there's not a one to one correlation between areas of high toxicity and population density. As an example, in Texas, Houston and San Antonio have high toxicity values, while the Dallas/Fort Worth are ends the period with fairly low toxicity. Comparatively, the more rural areas of Longview and Tyler are very high toxicity. 

Regions that stand out the most include the northern border of Kentucky, the regions surrounding Chicago, the border between New Jersey and Pennsylvania, and the westernmost section of the gulf coast.

A closer view of the Texan region of the gulf coast is shown below. 

![](https://raw.githubusercontent.com/DukeStatSci/thesis-sp18-driscoll-envjustice/master/index/figure/texas.gif)

Over the 1990-2013 period, we see an incredible reduction of toxicity in the Dallas/Fort Worth area, going from an area with a large center of extremely high toxicity, to mid range toxicity. Much of this improvement happens before 2000, where we see the area of 15,000+ toxicity drastically reduce in size. Despite a large overall reduction, the areas with the most sustained high toxicity are Houston, Longview and Beaumont. Some larger cities, like San Antonio, Austin and El Paso show much lower toxicity levels by 2013.

<!--chapter:end:04-eda.Rmd-->

# Methodology {#ref-labels}

## Geographic Level

The question we would like to pose - how the distributions of toxicity that individuals experience over time are predicted by their complex, multidimensional identities - is inherently intended to use individuals as the unit of analysis. Until now environmental justice work has used census geographies or point sources as the unit of analysis. 

We depend on two data sources, the disaggregated RSEI toxic release data (as compiled to contain only releases that are consistently reported between 1990 and 2010) as well as relevant demographic information from the Census. 

RSEI toxicity data can be obtained at extremely fine level (the 800m by 800m grid across the United States,) but the finest grain Census data is available at is the block level, where blocks contain between 0 and a few thousand people. At such low geographic levels, cross tabulations aren't available for demographics due to identifiability concerns. Using a low level of geography (like census blocks or block groups) is important for the environmental aspect of this analysis, since environmental hazards can be very localized, especially along neighborhood lines in urban areas. 

Unfortunately, the availability of cross tabulations is equally important to the goal of this work in examining inequality of environmental burden held by minority groups in the United States. The intersection of social identities, especially those steeped in systems of oppression, is extremely important for identifying unequal burdens. For example, low income populations across the board may be more likely to experience environmental hazards, but low income minority populations may be much more likely than low income white populations to experience extreme hazard. The intersections of demographic characteristics, such as race and income or race and education are likely to be important in teasing out the true inequality burden. 

We combine the computed aggregated toxicity for each block group and the demographic data. Now for each census geography, we have toxicity information as well as demographic data. 

|block       |concentration|area    |total_pop|white|black|
|------------|-------------|--------|---------|-----|-----|
|010010201001|627.3050     |6.520168|530      |447  |83   |
|010010201002|499.6298     |8.486690|1282     |1099 |126  |
|010010202001|578.8312     |3.137173|1274     |363  |824  |
|010010202002|756.3733     |1.962949|944      |458  |477  |
|010010203001|637.7356     |5.907125|2538     |2152 |384  |
|...         |...          |...     |...      |...  |...  |

We can aggregate to a national distribution of experienced toxicity by weighting each block toxicity by the number of people that experience it. This approach is restricted by Census data availability, since we can only build a distribution for each of the cross tabulations we have available. For higher levels of geography (where we might, for example, have race by income) we would be able to build national distributions for each income by race group.

In the case of the table above, to build a distribution for the white population, we would assign 447 people a toxicity of ~627, 1099 people a toxicity of ~499 and so on until we have the full distribution of toxicities experienced by the white population.

To choose the level of aggregation at which we calculate toxicity distributions, we create the overall toxicity distribution for Americans at each of the levels of geography. The process described can be executed with the data shown above, or at a cruder level of geography, such as state or region. Using block group as the smallest form of geography, and state as the largest we build toxicity distributions at each level of aggregation. 

```{r ecologicalFallacy, echo = FALSE, fig.width=10, fig.height=5, message = FALSE}
#import toxicity data
bg2010 = as.data.frame(fread("data/toxic/bg/toxic_2010_2010_blockgroup.csv"))

#import census data
census_bg = fread("data/ecologicalFallacy/census_bg_race.csv", skip = 1)
census_tract = fread("data/ecologicalFallacy/census_tract_race.csv")
census_county = fread("data/ecologicalFallacy/census_county_race.csv", skip = 1)
census_state = fread("data/ecologicalFallacy/census_state_race.csv", skip = 1)

#munge census data
census_bg = select(census_bg, Geo_FIPS, SE_T013_001, SE_T013_002, SE_T013_003)
names(census_bg)  = c("fips", "total", "white", "black")
census_bg$fips = str_pad(census_bg$fips, 12, pad = "0", "left")
census_tract = select(census_tract, Geo_FIPS, SE_T013_001, SE_T013_002, SE_T013_003)
names(census_tract)  = c("fips", "total", "white", "black")
census_county = select(census_county, Geo_FIPS, SE_T013_001, SE_T013_002, SE_T013_003)
names(census_county)  = c("fips", "total", "white", "black")
census_county$fips = str_pad(census_county$fips, 5, pad = "0", side = "left")
census_state = select(census_state, Geo_FIPS, SE_T013_001, SE_T013_002, SE_T013_003)
names(census_state)  = c("fips", "total", "white", "black")

#merge census and toxicity data
tract2010 = fread("data/ecologicalFallacy/toxic_2010_2010_tract.csv")
tract2010 = merge(tract2010, census_tract, by.x = "block", by.y = "fips")
county2010 = fread("data/ecologicalFallacy/toxic_2010_2010_county.csv")
county2010 = merge(county2010, census_county, by.x = "block", by.y = "fips")
state2010 = fread("data/ecologicalFallacy/toxic_2010_2010_state.csv", data.table = FALSE)
state2010 = merge(state2010, census_state, by.x = "block", by.y = "fips")
bg2010 = merge(bg2010, census_bg, by.x = "block", by.y = "fips")

#plot national distributions
g = ggplot() + geom_density(aes(concentration, weight = white/sum(white), color = "County"), bw = 0.08, data = county2010)
g = g + geom_density(aes(concentration, weight = white/sum(white), color = "State"), bw = .1, data = state2010)
g = g + geom_density(aes(concentration, weight = white/sum(white), color = "Block Group"), bw = 0.08, size = 1, data = bg2010)
g = g + geom_density(aes(concentration, weight = white/sum(white), color = "Tract"), bw = 0.05, size = 1, data = tract2010)
g = g + labs(x = "Log Toxicity", colour = "Geographic Level", caption = "(as assigned by different levels of geography)", title = "Distribution of Toxicity for US Population")
g = g + theme(axis.text=element_text(size = 6), legend.text = element_text(size = 7), legend.title = element_text(size = 8))
g = g + scale_x_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                          labels = scales::trans_format("log10", scales::math_format(10^.x))) +
      annotation_logticks(
        short = unit(.5,"mm"),
        mid = unit(2,"mm"), 
        long = unit(3.5,"mm"),
        sides = "b",
        color = "gray65") 
g
```

As expected, the state level assignment is a poor approximation of the lower level assignments. Given that we are assigning each individual the mean toxicity in their entire state, we are eliminating most of the variation from the data. Interestingly tract and county data seems to build a distribution quite similar to the block group level assignment. Initial results were replicated using all 3 levels of assignment, and conclusions remained the same. This may be because the block group level is aggregating a large enough group of our fine grain toxicity data that it has already lost the street block by street block variation that we had deemed so crucial, meaning aggregating several block groups gives us a conceptually equivalent 'neighborhood' level of aggregation. 

The ecological fallacy is a constant discussion in environmental justice literature. It is speculated to be the reason for varying results, as toxicity data can be sensitive to geographic level of analysis, time of collection, and area. In this case, conclusions appear to be relatively robust to unit of assignments.


## Simulation
```{r densityCalcs, include = FALSE}
density_black = ewcdf(bg2010$concentration, weights = bg2010$black/sum(bg2010$black))
black2010 = round(quantile(density_black, 0.75), 2)
density_overall = ewcdf(bg2010$concentration, weights = bg2010$total/sum(bg2010$total))
overallperc = round(density_overall(black2010), 4)*100
```

### Process

To examine how environmental burden changes over time for minority groups we use simulation to tease apart the forces at play in each group's changing distributions. We expect the mean of minority distributions to reduce over time for two reasons: the toxicity distribution for the entire population is slowly shifting right and compressing as we see improvements in environmentally friendly production technology and more comprehensive environmental regulation; secondly, we hope that with Title VI protections and the work of civil rights advocates, minority communities will be better equipped to mobilize against polluters, shifting the mean of minority distribution right relative to the overall distribution.

These two explanations for decreasing toxicity can translate into two descriptors of distributional change:
 
  * distributional convergence: where inequality is reduced due to compression of the overall distribution, disproportionately improving toxicity for those at the right tail. 
  
  * positional convergence: where inequality is reduced due to shifting distributions, reducing the difference between means of each distribution.
  
Positional convergence is of primary interest, since it would allow us to look at how much 'true' change there has been. By removing the distributional convergence we are able to compare the current observed reductions in inequality to what those changes would have been if minority populations had held static their position in the overall distribution.

In order to find the positional convergence of minority distributions over the period of study, we use the percentiles that minority individuals held in the overall distribution at the start of the period of study and propagate them forward to simulate what each group's distribution would have been in later years. This simulation procedure was first discussed by Bayer, Patrick and Kerwin as a method of identifying the true gains in 'Black-White Earning Differences' (2016). 

This simulation proceeds as follows:

* Build an empirical distribution of toxicity experienced for the entire population and for each group of interest in the starting year. 

* Sample individuals from the empirical distributions of the groups of interest. 

* For each sampled toxicity value, find the percentile it holds in the empirical distribution for the entire population in the starting year. 

* Create an empirical distribution for the entire population in the ending year. 

* For each sampled percentile, find the corresponding toxicity value in the full empirical distribution of the ending year and compile results to create a simulated group of interest.

Using this method we can hold constant the place each individual (and more broadly each group) holds in the overall distribution, but follow the changes in the distribution as a whole. The collection of values simulated now represents the toxicity each individual or group would have experienced if they had held the same relative position in the overall toxicity distribution.

If there had been positional improvement for a group, we would expect the simulated distributions to paint a bleaker picture of the inequalities of environmental burden borne than the observed distribution of the ending year. 

### Accuracy

In order to estimate the standard errors of simulated estimates of the 5^th^, 50^th^ and 95^th^ percentiles, we repeatedly execute the simulation process on data for the black population in 1990. Simulating the changes of the entire black population would mean dealing with a population of around 29 million, but with a large sample we should be able to get a good estimate. 

To determine how large the sample needs to be, we run the simulation 20 times for each n tested and show the mean and standard error of the estimate. 

```{r simulationSE, echo = FALSE, warning = FALSE, message = FALSE, fig.width=8, fig.height=6}
sim_se_05 = read_csv("data/bootstrap_simulation_se_05.csv")
sim_se_50 = read_csv("data/bootstrap_simulation_se_50.csv")
sim_se_95 = read_csv("data/bootstrap_simulation_se_95.csv")

s5 = ggplot() + 
  geom_ribbon(aes(x = n, ymin = mean-sd, ymax = mean+sd), alpha=0.2, data = sim_se_05) +
  geom_line(aes(x = n, y = mean), data = sim_se_05) +
  labs(x = "Size of simulated group (n)", y = "Simulated 5th Percentile") + coord_cartesian(ylim=c(40, 100)) + scale_x_continuous(labels = scales::comma) + geom_vline(xintercept = 50000, color = "darkgrey") + theme(axis.title.x=element_blank(), axis.text.y=element_text(size=8))

s50 = ggplot() + 
  geom_ribbon(aes(x = n, ymin = mean-sd, ymax = mean+sd), alpha=0.2, data = sim_se_50) +
  geom_line(aes(x = n, y = mean), data = sim_se_50) +
  labs(x = "Size of simulated group (n)", y = "Simulated 50th Percentile") + coord_cartesian(ylim=c(7000, 9000)) + scale_x_continuous(labels = scales::comma) + geom_vline(xintercept = 50000, color = "darkgrey") + theme(axis.title.x=element_blank(), axis.text.y=element_text(size=7))

s95 = ggplot() + 
  geom_ribbon(aes(x = n, ymin = mean-sd, ymax = mean+sd), alpha=0.2, data = sim_se_95) +
  geom_line(aes(x = n, y = mean), data = sim_se_95) +
  labs(x = "Size of simulated group (n)", y = "Simulated 95th Percentile") + coord_cartesian(ylim=c(80000, 140000)) + scale_x_continuous(labels = scales::comma) + geom_vline(xintercept = 50000, color = "darkgrey") + theme(axis.text.y=element_text(size=6), axis.text.x=element_blank())

grid.arrange(s5, s50, s95, ncol=1)

```

For the 5^th^ percentile, a relatively small sample produces a fairly stable result, as standard error does not reduce substantially with n larger than 20,000. Due to the extreme right skew of the data, the 95^th^ percentile requires a larger sample to reach a stable estimate. Still n = 50,000 is sufficient, and that size is used for all samples. 

<!--chapter:end:05-methods.Rmd-->

# Results {#organization}

## Trends in Minority Toxicity Burden

Using data at the tract level, we assign the average concentration across each tract to the counts of each population group in the tract. This allows us to build four distributions: toxicity for the white population, toxicity for the black population, toxicity for the Hispanic population, and toxicity for all other groups. In this case, Hispanic is not a mutually exclusive group, and the race groups may contain ethnically Hispanic individuals. 

For each of the distributions, the 5^th^, 50^th^, and 95^th^ percentiles are calculated for each year. The 5^th^ and 95^th^ percentiles are especially of interest, as they represent the non-polluted neighborhoods that each group has access to and the level of pollution trap that each group falls in to. Clearly, for all variables, lower toxicity is better. 

Plots describing the trends for each percentile are shown below. On the left is the log toxicity for each percentile over time. On the right is the toxicity minorities experience relative to the white distribution. These values are computed as the net (not log) toxicity of the given percentile for a group divided by the net toxicity of the given percentile for the white distribution.


```{r percentileCalcs, echo = FALSE, message = FALSE, warning = FALSE}
library(plyr)

sim05 = fread("data/simulation05.csv", data.table = FALSE)
sim50 = fread("data/simulation50.csv", data.table = FALSE)
sim95 = fread("data/simulation95.csv", data.table = FALSE)
se_race_05 = fread("data/bootstrap_race_se_05.csv", data.table = FALSE)
se_race_50 = fread("data/bootstrap_race_se_50.csv", data.table = FALSE)
se_race_95 = fread("data/bootstrap_race_se_95.csv", data.table = FALSE)

get_perc = function(data, quant, variables = c("pop", "white", "black", "hispanic", "other"), sim = NA, se = NA) {
  new = sort(unique(data$year), decreasing = FALSE)
  for (var in variables) {
    new = cbind(new, ddply(data, .(year), function(x) weighted.quantile(x$concentration, x[, var]/sum(x[, var]), quant, na.rm = TRUE))[, 2])
  }
  new = as.data.frame(new)
  names(new) = c("year", variables)
  if (!is.na(sim)) {
    new = merge(new, sim, by = "year")
  }
  if (!is.na(se)) {
    new = merge(new, se, by = "year")
  }
  return(new)
}

perc05 = get_perc(data, 0.05, sim = sim05)
perc50 = get_perc(data, 0.50, sim = sim50)
perc95 = get_perc(data, 0.95, sim = sim95)

#msa_perc05 = get_perc(dense_data, 0.05, sim = sim05)
#msa_perc50 = get_perc(dense_data, 0.50, sim = sim50)
#msa_perc95 = get_perc(dense_data, 0.95, sim = sim95)
```

```{r createPlots, echo = FALSE, message = FALSE, fig.width=8, fig.height=4}
tox = function(cur_data, perc, legend = FALSE, smooth = FALSE, log = TRUE) {
  g = ggplot(data = cur_data) + 
    geom_line(aes(x = year, y = white, color = "white")) +
    geom_line(aes(x = year, y = black, color = "black")) + 
    geom_line(aes(x = year, y = hispanic, color = "hispanic")) + 
    geom_line(aes(x = year, y = other, color = "other")) + 
    labs(x = "Year", y = "Toxicity", title = paste0(perc, "th PCTL Group Toxicity"))
  if (legend == FALSE) {
    g = g + guides(color = FALSE)
  }
  if (smooth == TRUE) {
    g = g +
      geom_line(aes(x = year, y = rollmean(black, 3, na.pad=TRUE), color = "black"), se = FALSE, size = 0.5, linetype = "twodash")  +
      geom_line(aes(x = year, y = rollmean(hispanic, 3, na.pad = TRUE), color = "hispanic"), se = FALSE, size = 0.5, linetype = "twodash") +
      geom_line(aes(x = year, y = rollmean(other, 3, na.pad = TRUE), color = "other"), se = FALSE, size = 0.5, linetype = "twodash") +
      geom_line(aes(x = year, y = rollmean(white, 3, na.pad = TRUE), color = "white"), se = FALSE, size = 0.5, linetype = "twodash")
  }
  if (log == TRUE) {
    g = g + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                          labels = scales::trans_format("log10", scales::math_format(10^.x))) +
      annotation_logticks(
        short = unit(.5,"mm"),
        mid = unit(2,"mm"), 
        long = unit(3.5,"mm"),
        sides = "l",
        color = "gray65") 
  }
  g
}

relative_tox = function(data, perc, legend = FALSE, smooth = FALSE) {
  g = ggplot(data) +
    labs(x = "Year", y = "Toxicity Relative to White Dist.", title = paste0(perc, "th PCTL Toxicity Relative to White Distribution"), colour = "Color") +
    theme(legend.position="bottom")
  if (smooth == TRUE) {
    g = g + 
      geom_line(aes(x = year, y = (white/white), color = "white")) +
      geom_line(aes(x = year, y = (black/white), color = "black"), alpha = 0.3)  +
      geom_line(aes(x = year, y = (hispanic/white), color = "hispanic"), alpha = 0.3) +
      geom_line(aes(x = year, y = (other/white), color = "other"), alpha = 0.3) +
      geom_line(aes(x = year, y = rollmean(black/white, 3, na.pad=TRUE), color = "black"), linetype = "twodash", size = 0.7)  +
      geom_line(aes(x = year, y = rollmean(hispanic/white, 3, na.pad = TRUE), color = "hispanic"), linetype = "twodash", size = 0.7) +
      geom_line(aes(x = year, y = rollmean(other/white, 3, na.pad = TRUE), color = "other"), linetype = "twodash", size = 0.7) 
  }
  else {
    g = g + 
      geom_line(aes(x = year, y = (white/white), color = "white")) +
      geom_line(aes(x = year, y = (black/white), color = "black"))  +
      geom_line(aes(x = year, y = (hispanic/white), color = "hispanic")) +
      geom_line(aes(x = year, y = (other/white), color = "other"))
  }
  if (legend == FALSE) {
    g = g + guides(color = FALSE)
  }
  g
}

pov_tox = function(cur_data, perc, legend = FALSE) {
  g = ggplot(data = cur_data) + 
    geom_line(aes(x = year, y = whiteh, color = "white")) +
    geom_line(aes(x = year, y = blackh, color = "black")) + 
    geom_line(aes(x = year, y = nativeh, color = "native")) + 
    geom_line(aes(x = year, y = asianh, color = "asian")) + 
    geom_line(aes(x = year, y = otherh, color = "other")) + 
    geom_line(aes(x = year, y = whitel, color = "white")) +
    geom_line(aes(x = year, y = blackl, color = "black")) + 
    geom_line(aes(x = year, y = nativel, color = "native")) + 
    geom_line(aes(x = year, y = asianl, color = "asian")) + 
    geom_line(aes(x = year, y = otherl, color = "other")) + 
    labs(x = "Year", y = "Group Toxicity", title = paste0(perc, "th PCTL Toxicity"), color = "Legend")
  if (legend == FALSE) {
    g = g + guides(color = FALSE)
  }
  g
}

g_legend = function(a.gplot) {
  tmp = ggplot_gtable(ggplot_build(a.gplot))
  leg = which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend = tmp$grobs[[leg]]
  return(legend)
}
```

```{r plottox05, echo = FALSE, fig.width=10, fig.height=4, warning = FALSE, message = FALSE}
five = tox(perc05, 5)
fifty = tox(perc50, 50)
ninetyfive = tox(perc95, 95)

five_rel = relative_tox(perc05, 5, smooth = TRUE)
fifty_rel = relative_tox(perc50, 50, smooth = TRUE)
ninetyfive_rel = relative_tox(perc95, 95, smooth = TRUE)

legend_grab = relative_tox(perc05, 5, legend = TRUE)
color_legend = g_legend(legend_grab)

legend_grab = ggplot(perc05) + geom_line(aes(x = year, y = black, linetype = "Observed")) + geom_line(aes(x = year, y = white, linetype = "3 Yr Moving Average")) + scale_linetype_manual(values=c("twodash", "solid")) + theme(legend.position="bottom") + labs(linetype = "Line type")
line_legend = g_legend(legend_grab)

grid.arrange(arrangeGrob(five, five_rel, nrow=1),
             arrangeGrob(color_legend, line_legend, nrow=1), nrow=2,heights=c(10, 1))
```

As we see in the 5^th^ percentile plots, the 5^th^ percentile of experienced toxicity is steadily decreasing for all groups. Given the y axis has been logged, and we see a linear trend, toxicity has seen an exponential drop over the years. There appear to be two distinct groups, with the black and 'other' groups significantly higher than the white and Hispanic groups in 1988, and even more distinctly separated by 2013. Though we see incredible improvements in toxicity for all groups, the relative improvement shows a different story. The difference for the 'other' minorities is most impressive, originally having 5^th^ percentile toxicity at approximately 1.5 times the rate of the white 5^th^ percentile, but ending at over 6 times the white 5^th^ percentile. 

From this plot we see that though minorities have had the largest net decreases in 5^th^ percentile toxicity, those gains are due to how much higher their original toxicity was. When framing improvements relative to the white population, there has been no improvement, in some cases relative toxicity has regressed.

```{r plottox50, echo = FALSE, fig.width=10, fig.height=4, warning = FALSE, message = FALSE}
grid.arrange(arrangeGrob(fifty, fifty_rel, nrow=1),
             arrangeGrob(color_legend, line_legend, nrow=1), nrow=2,heights=c(10, 1))
```

The toxicity changes for the 50^th^ percentile tell a very different story. Again, we see linear improvement in the logged toxicity plot, indicating an exponential decrease in the toxicity experienced by the 50^th^ percentile of all populations. At the 50^th^ percentile minority groups have improved faster than their white counterparts, meaning that the relative toxicity of all groups is converging towards the 50^th^ percentile of the white distribution. 

```{r plottox95, echo = FALSE, fig.width=10, fig.height=4, warning = FALSE, message = FALSE}
grid.arrange(arrangeGrob(ninetyfive, ninetyfive_rel, nrow=1),
             arrangeGrob(color_legend, line_legend, nrow=1), nrow=2,heights=c(10, 1))
```

95^th^ percentile toxicity is of the most of interest. The difference between estimates for white and minorities is at the level of orders of magnitude at the 5^th^, 50^th^, and 95^th^ percentiles, but at the 95^th^ percentile an order of magnitude is more significant than in the 5^th^ percentile. An interesting difference is that at the high end of the distribution, we see the 'other' minority group has a relative toxicity close to 1, where in previous plots the other group had significantly worse relative toxicity. It's important to consider that race groups had to be combined to maintain consistency over the time period, meaning many groups are represented in the 'other' category. The difference we see in the trends may be due to the populations that are more likely to live in areas at the 95^th^ percentile of toxicity because we are following trends of different groups. The Hispanic group previously performed closest to the white group, at the 95^th^ percentile the Hispanic group performs more similarly to the black distribution. 

Examining the changes in each of these plots independently gives us a glimpse at how the distributions as a whole are shifting. The lack of change, or even worsening, of relative toxicity for the black and other distributions at the 5^th^ percentile may be indicative of barriers minorities face in access to clean communities. As wealthier communities are getting ever cleaner, minorities may still unable to gain access to them, meaning less improvement in the low tail of the minority distributions.  

Comparatively, the changes at the 50^th^ percentile show that minorities have all consistently improved faster than the white 50^th^ percentile. 

In the 95^th^ percentile, we see the 'other' group performing similarly to the white distribution, while the black and Hispanic distributions improve until the early 2000's, and then flatten out or rise relative to the white distribution. We are seeing a widening gap in the 5^th^ percentile, a closing gap in the 50^th^ percentile, and stagnation of change in the 95^th^. 

## Trends in Simulated Minority Toxicity Burden

Being able to build the distributions of toxicity that each group experiences over time allows us to see how relative toxicity burden has changed over time. Yet the changes presented above are the net changes experienced by each group. Given minorities are more likely to be in the right tail of the distribution, any compression of that tail would result in both a net improvement for minority groups and a relative improvement to the white distribution. Those changes, though positive, don't represent a true change in the position minorities hold in the distribution, as their relative position is still in the high percentiles of the distribution. 

To find how much of the change is attributable to changes of minority position, we use the simulation method discussed in Section 3. By holding the percentile of each individual constant, but applying it to the overall distribution in a later year, we can see what the minority distribution would have looked like if the minority position within the overall distribution had not changed. 

Improvement will only represent justice when all groups are equally likely to be represented at any given percentile, not when the distribution is compressed enough that differences are small. 


```{r changePlots, echo = FALSE, warning = FALSE, fig.width=10, fig.height=4}
sim_tox = function(cur_data, perc, legend = FALSE, smooth = FALSE, log = TRUE) {
  g = ggplot(data = cur_data) + 
        labs(x = "Year", y = "Toxicity", title = paste0(perc, "th PCTL Group Toxicity"))
  if (smooth == TRUE) {
    g = g +
      geom_line(aes(x = year, y = white, color = "white"), alpha = 0.3) +
      geom_line(aes(x = year, y = black, color = "black"), alpha = 0.3) + 
      geom_line(aes(x = year, y = hispanic, color = "hispanic"), alpha = 0.3) + 
      geom_line(aes(x = year, y = other, color = "other"), alpha = 0.3) + 
      geom_line(aes(x = year, y = rollmean(black, 3, na.pad=TRUE), color = "black"), size = 0.5)  +
      geom_line(aes(x = year, y = rollmean(hispanic, 3, na.pad = TRUE), color = "hispanic"), size = 0.5) +
      geom_line(aes(x = year, y = rollmean(other, 3, na.pad = TRUE), color = "other"), size = 0.5) +
      geom_line(aes(x = year, y = rollmean(white, 3, na.pad = TRUE), color = "white"), size = 0.5)
  } 
  else {
     g = g +
      geom_line(aes(x = year, y = white, color = "white")) +
      geom_line(aes(x = year, y = black, color = "black")) + 
      geom_line(aes(x = year, y = hispanic, color = "hispanic")) + 
      geom_line(aes(x = year, y = other, color = "other"))
  }
  g = g + geom_line(aes(x = year, y = sim_b, color = "black"), linetype = "dashed", size = 0.7) + 
    geom_line(aes(x = year, y = sim_o, color = "other"), linetype = "dashed", size = 0.7) +
    geom_line(aes(x = year, y = sim_h, color = "hispanic"), linetype = "dashed", size = 0.7) 
  if (legend == FALSE) {
    g = g + guides(color = FALSE)
  }
  if (log == TRUE) {
    g = g + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                          labels = scales::trans_format("log10", scales::math_format(10^.x))) +
      annotation_logticks(
        short = unit(.5,"mm"),
        mid = unit(2,"mm"), 
        long = unit(3.5,"mm"),
        sides = "l",
        color = "gray65") 
  }
  g
}

relative_sim = function(data, perc, legend = FALSE, smooth = FALSE) {
  g = ggplot(data) +
    labs(x = "Year", y = "Toxicity Relative to White Dist.", title = paste0(perc, "th PCTL Toxicity Relative to White Distribution")) + 
    theme(legend.position="bottom") +
    geom_line(aes(x = year, y = (white/white), color = "white")) 
  if (smooth == TRUE) {
    g = g + 
      geom_line(aes(x = year, y = (black/white), color = "black"), alpha = 0.2)  +
      geom_line(aes(x = year, y = (hispanic/white), color = "hispanic"), alpha = 0.2) +
      geom_line(aes(x = year, y = (other/white), color = "other"), alpha = 0.2) +
      geom_line(aes(x = year, y = rollmean(black/white, 3, na.pad=TRUE), color = "black"), size = 0.7, alpha = 0.45)  +
      geom_line(aes(x = year, y = rollmean(hispanic/white, 3, na.pad = TRUE), color = "hispanic"), size = 0.7, alpha = 0.45) +
      geom_line(aes(x = year, y = rollmean(other/white, 3, na.pad = TRUE), color = "other"), size = 0.7, alpha = 0.45) +
      geom_line(aes(x = year, y = rollmean(sim_b/white, 3, na.pad = TRUE), color = "black"), linetype = "dashed", size = 0.7) + 
      geom_line(aes(x = year, y = rollmean(sim_o/white, 3, na.pad = TRUE), color = "other"), linetype = "dashed", size = 0.7) +
      geom_line(aes(x = year, y = rollmean(sim_h/white, 3, na.pad = TRUE), color = "hispanic"), linetype = "dashed", size = 0.7) 
  } else {
    g = g + 
      geom_line(aes(x = year, y = (black/white), color = "black"), alpha = 0.45)  +
      geom_line(aes(x = year, y = (hispanic/white), color = "hispanic"), alpha = 0.45) +
      geom_line(aes(x = year, y = (other/white), color = "other"), alpha = 0.45) +
      geom_line(aes(x = year, y = sim_b/white, color = "black"), linetype = "dashed", size = 0.7) + 
      geom_line(aes(x = year, y = sim_o/white, color = "other"), linetype = "dashed", size = 0.7) +
      geom_line(aes(x = year, y = sim_h/white, color = "hispanic"), linetype = "dashed", size = 0.7) 
  }
  if (legend == FALSE) {
    g = g + guides(color = FALSE)
  }
  g
}

legend_grab = ggplot(perc05) + geom_line(aes(x = year, y = black, linetype = "Observed")) + geom_line(aes(x = year, y = white, linetype = "Simulated")) + scale_linetype_manual(values=c("solid", "dashed")) + theme(legend.position="bottom") + labs(linetype = "Line type")
line_legend = g_legend(legend_grab)
```

```{r, echo = FALSE, fig.width=10, fig.height=4, warning = FALSE}
grid.arrange(arrangeGrob(sim_tox(perc05, 5), relative_sim(perc05, 5), nrow=1),
              arrangeGrob(color_legend, line_legend, nrow=1), nrow=2,heights=c(10, 1))
```

The 5^th^ percentile of the simulated black distribution is significantly higher than that of the true black distribution, rising to approximately 12 times that of the white distribution. This means that more black individuals were able to move to locations with lower toxicity or had dramatic improvements in neighborhood toxicity. If they had maintained their position in the overall distribution, they would have experienced significantly higher toxicities. Interestingly, the opposite is true for the 'other' distribution. Their true 5^th^ percentile has significantly worse toxicity than their simulated 5^th^ percentile. This indicates that non-black minorities at the low end of the distribution hold worse places in the overall distribution than they did in 1990. 

```{r, echo = FALSE, fig.width=10, fig.height=4, warning = FALSE}
grid.arrange(arrangeGrob(sim_tox(perc50, 50), relative_sim(perc50, 50), nrow=1),
             arrangeGrob(color_legend, line_legend, nrow=1), nrow=2,heights=c(10, 1))
```

Changes at the 50^th^ percentile were impressive in the initial analysis, and remain that way. The simulated distributions still show improvement, but very minor compared to the observed improvement. The simulated black 50^th^ percentile drops from 3 times to 2.75 times the white 50^th^ percentile, where the true distribution drops from 3 times to 1.5 times the white distribution. All the simulations show the same pattern, with the Hispanic group showing the largest difference between true and simulated 50^th^ percentile, the simulated group ending at 2.25 times the white distribution, and the true group ending at 0.75 times the white distribution. 

Interpreting the differences in simulated and true values as the portion of change attributable to the position each group holds in the overall distribution, it seems that there has been change in the positions minorities hold in the overall toxicity distribution.

```{r, echo = FALSE, fig.width=10, fig.height=4, warning = FALSE}
grid.arrange(arrangeGrob(sim_tox(perc95, 95), relative_sim(perc95, 95), nrow=1),
             arrangeGrob(color_legend, line_legend, nrow=1), nrow=2,heights=c(10, 1))
```

Simulations of the 95^th^ percentile show even less improvement, meaning nearly all the change minorities experience is from moving towards a lower percentile in the overall distribution. At the 95^th^ percentile the black distribution shows the largest difference to it's simulated distribution. The simulated black 95^th^ percentile ends at 2.25 times that of the white distribution, while the observed black 95^th^ percentile ends at 1.75 times that of the white distribution. 

From this we see that the distribution of percentiles occupied by minority groups was originally shifted towards the higher percentiles, but over time have shifted right. Plotting the percentiles of each group within their full distribution that year, we see that in 1990 all minority groups are strongly skewed towards the higher end of the distribution. As time goes on, more minorities exist in the lower percentiles, and more whites exist in the higher percentiles of the distribution.

```{r densityplots, warning = FALSE,echo = FALSE, fig.width=10, fig.height=15, message = FALSE}
quants = read_csv("data/quantiles.csv")

quants$y2013 = "2013"
quants$y2000 = "2000"
quants$y1990 = "1990"

legend_grab = ggplot(quants) + 
  geom_density(aes(hispanic2013, linetype = y2013), alpha = 0.05, size = 1) + 
  geom_density(aes(hispanic2000, linetype = y2000), alpha = 0.05, size = 1) + 
  geom_density(aes(hispanic1990, linetype = y1990), alpha = 0.05, size = 1) +
  labs(x = "Percentile", y = "Density") + ylim(0, 1.8) + theme(legend.position = "bottom") + labs(linetype = "Year")

year_legend = g_legend(legend_grab)

pblack = ggplot(quants) + 
  geom_density(aes(black2013, fill = "black", color = "black", linetype = y2013), alpha = 0.05, size = 1) + 
  geom_density(aes(black2000, fill = "black", color = "black", linetype = y2000), alpha = 0.05, size = 1) + 
  geom_density(aes(black1990, fill = "black", color = "black", linetype = y1990), alpha = 0.05, size = 1) + 
  labs(x = "Percentile", y = "Density") +
  guides(color = FALSE, fill = FALSE, linetype = FALSE) + ylim(0, 1.8)

pwhite = ggplot(quants) + 
  geom_density(aes(white2013, linetype = y2013), fill = "mediumorchid", color = "mediumorchid" ,alpha = 0.05, size = 1) + 
  geom_density(aes(white2000, linetype = y2000), fill = "mediumorchid", color = "mediumorchid", alpha = 0.05, size = 1) + 
  geom_density(aes(white1990, linetype = y1990), fill = "mediumorchid", color = "mediumorchid", alpha = 0.05, size = 1) +
  labs(x = "Percentile", y = "Density") +
  guides(color = FALSE, fill = FALSE, linetype = FALSE) + ylim(0, 1.8)

phispanic = ggplot(quants) + 
  geom_density(aes(hispanic2013, linetype = y2013), fill = "olivedrab4", color = "olivedrab4" ,alpha = 0.05, size = 1) + 
  geom_density(aes(hispanic2000, linetype = y2000), fill = "olivedrab4", color = "olivedrab4", alpha = 0.05, size = 1) + 
  geom_density(aes(hispanic1990, linetype = y1990), fill = "olivedrab4", color = "olivedrab4", alpha = 0.05, size = 1) +
  labs(x = "Percentile", y = "Density") +
  guides(color = FALSE, fill = FALSE, linetype = FALSE) + ylim(0, 1.8)

grid.arrange(arrangeGrob(pwhite, pblack, phispanic, nrow=3),
             arrangeGrob(color_legend, year_legend, nrow=1), nrow = 2,heights=c(10, 1))
```


## Interacting Risk Cases

Above we have seen the differing experiences of changing toxicities by race. We find that toxicity is significantly improving for all, but relative improvement has begun to stagnate for minority groups at some levels. This begs the question of what the trends are for individuals with interacting risk cases. Given the multifaceted social identities individuals hold, any single metric will be missing part of the pattern. Ideally we would be able to represent the complex power structures and dynamic social categorizations in our society, but with limited data, and the inherent complexity of the problem, we can begin to broach this problem by looking at the intersection of two commonly discussed risk groups. In this case we examine how the trends of experienced toxicity vary for each race group when considering income levels.

To do so we split households in to low income (under 25,000), medium (between 25,000 and 75,000), and high income (over 75,000).

```{r incPlots, include = FALSE, warning = FALSE, fig.width=10, fig.height=8}
pov = data[!is.na(data$blackh), ]
pov05 = get_perc(pov, 0.05, variables = names(data)[10:18])
pov50 = get_perc(pov, 0.50, variables = names(data)[10:18])
pov95 = get_perc(pov, 0.95, variables = names(data)[10:18])
max = max(pov95)
min = min(pov05)
legend_grab = ggplot(pov05) + geom_line(aes(x = year, y = blackh, linetype = "Income of 75k+")) + geom_line(aes(x = year, y = blackl, linetype = "Income btwn 25-75k")) + scale_linetype_manual(values=c("solid", "dashed")) + theme(legend.position="bottom") + labs(linetype = "Line type")
line_income_legend = g_legend(legend_grab)

black = ggplot() + 
  geom_line(aes(x = year, y = blackh), color = "coral2", linetype = "longdash", pov95) +
  geom_line(aes(x = year, y = blackm), color = "coral2", size = 0.7, pov95) + 
  geom_line(aes(x = year, y = blackl), color = "coral2", linetype = "dotted", pov95) + 
  geom_line(aes(x = year, y = blackh), color = "coral2", linetype = "longdash", pov05) +
  geom_line(aes(x = year, y = blackm), color = "coral2", size = 0.7, pov05) + 
  geom_line(aes(x = year, y = blackl), color = "coral2", linetype = "dotted", pov05) +  
  geom_line(aes(x = year, y = blackh), color = "coral2", linetype = "longdash", pov50) +
  geom_line(aes(x = year, y = blackm), color = "coral2", size = 0.7, pov50) + 
  geom_line(aes(x = year, y = blackl), color = "coral2", linetype = "dotted", pov50) + 
  scale_y_log10(limits = c(min, max), breaks = scales::trans_breaks("log10", function(x) 10^x), labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(.5,"mm"), mid = unit(2,"mm"), long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  labs(x = "Year", y = "Log Toxicity", main = "Toxicity for each income group in black population")

white = ggplot() + 
  geom_line(aes(x = year, y = whiteh), color = "mediumorchid", linetype = "longdash", pov95) +
  geom_line(aes(x = year, y = whitem), color = "mediumorchid", size = 0.7, pov95) + 
  geom_line(aes(x = year, y = whitel), color = "mediumorchid", linetype = "dotted", pov95) + 
  geom_line(aes(x = year, y = whiteh), color = "mediumorchid", linetype = "longdash", pov05) +
  geom_line(aes(x = year, y = whitem), color = "mediumorchid", size = 0.7, pov05) + 
  geom_line(aes(x = year, y = whitel), color = "mediumorchid", linetype = "dotted", pov05) +  
  geom_line(aes(x = year, y = whiteh), color = "mediumorchid", linetype = "longdash", pov50) +
  geom_line(aes(x = year, y = whitem), color = "mediumorchid", size = 0.7, pov50) + 
  geom_line(aes(x = year, y = whitel), color = "mediumorchid", linetype = "dotted", pov50) + 
  scale_y_log10(limits = c(min, max), breaks = scales::trans_breaks("log10", function(x) 10^x), labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(.5,"mm"), mid = unit(2,"mm"), long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  labs(x = "Year", y = "Log Toxicity", main = "Toxicity for each income group in white population")

hisp = ggplot() + 
  geom_line(aes(x = year, y = hisph), color = "olivedrab4", linetype = "longdash", pov95) +
  geom_line(aes(x = year, y = hispm), color = "olivedrab4", size = 0.7, pov95) + 
  geom_line(aes(x = year, y = hispl), color = "olivedrab4", linetype = "dotted", pov95) + 
  geom_line(aes(x = year, y = hisph), color = "olivedrab4", linetype = "longdash", pov05) +
  geom_line(aes(x = year, y = hispm), color = "olivedrab4", size = 0.7, pov05) + 
  geom_line(aes(x = year, y = hispl), color = "olivedrab4", linetype = "dotted",  pov05) +  
  geom_line(aes(x = year, y = hisph), color = "olivedrab4", linetype = "longdash", pov50) +
  geom_line(aes(x = year, y = hispm), color = "olivedrab4", size = 0.7, pov50) + 
  geom_line(aes(x = year, y = hispl), color = "olivedrab4", linetype = "dotted", pov50) + 
  scale_y_log10(limits = c(min, max), breaks = scales::trans_breaks("log10", function(x) 10^x), labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(.5,"mm"), mid = unit(2,"mm"), long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  labs(x = "Year", y = "Log Toxicity", main = "Toxicity for each income group in hispanic population")
```

First we examine How the 5^th^, 50^th^ and 95^th^ percentiles differ for the black distribution. Dotted lines represent the low income group, solid lines represent the medium income group, and dashed lines represent the high income group. In this case the 50^th^ and 95^th^ percentile act as would be expected, with the high income group experiencing lower toxicity across the board. However, the 5^th^ percentile shows the inverse pattern, with high income households experiencing higher toxicity. One reason this could be true is that high income individuals may be more likely to live in the more toxic suburban or urban areas, rather than rural areas. 

```{r}
grid.arrange(black, arrangeGrob(color_legend, line_income_legend, nrow=1), nrow=2,heights=c(10, 1))
```

In the white population we see a similar pattern. The 95^th^ percentile continues to show the expected behavior at the 95^th^ percentile, but in both the 50^th^ and 5^th^ percentiles the high income group has a significantly higher toxicity. 

```{r}
grid.arrange(white, arrangeGrob(color_legend, line_income_legend, nrow=1), nrow=2,heights=c(10, 1))
```

The Hispanic group shows exactly the opposite pattern of the white distribution, with the high income distribution experiencing higher toxicity in the 50^th^ and 95^th^ percentiles, and lower toxicity in the 5^th^ percentile. In the 50^th^ and 95^th^ percentile, the differences between toxicities experienced by each income group are minimal. The 5^th^ percentile, however, shows significantly lower toxicities experienced by the high income group. 

```{r}
grid.arrange(hisp, arrangeGrob(color_legend, line_income_legend, nrow=1), nrow=2,heights=c(10, 1))
```

Interestingly, the group with the largest differences between high and low income across all percentile groups appears to be the white distribution. This may indicate that  housing discrimination and neighborhood sorting may be relevant areas to study. Given the rational sociopolitical reasons theorized for environmental justice origins, it may be that income is less predictive for minorities due to reduced choice in housing locations, meaning that even given the economic viability of escaping toxicity is less feasible. 

```{r}
grid.arrange(arrangeGrob(black, hisp, white, nrow=1), arrangeGrob(color_legend, line_income_legend, nrow=1), nrow=2, heights=c(10, 1))
```

Seeing these results together we find they aren't internally consistent, and do not follow the expected pattern. As hypothesized in discussion of the black distributions, it may be that there are confounding factors that aren't being addressed. Intersectionality requires a more complex view of identities as explanation of lived experiences, and these factors do not appear to be enough to understand the underlying patterns. Potential confounding areas to explore include: population density, geographic area, prevalence of local manufacturing jobs, level of political engagement, and education levels. 

## Exploration of Quantile Regression

Previous sections have focused on teasing apart patterns in the vast amounts of data we have. We find large differences in the toxicity experienced, but may be limited by the choices in division we make. Given we only investigate income as a relevant variable, there are likely patterns in the data that aren't being examined. 

In order to better tease out relationships in the data, and for easy interpretation of coefficients, a functionally similar analysis can be done with quantile regression, focusing on the computed parameters as indicators of the differences in experienced toxicity. 

To illustrate the form this model could take, we build preliminary quantile regression models on the 5^th^, 50^th^, and 95^th^ percentiles of the toxicity distribution. To predict log toxicity, we use the year, demographic information, population density and quadratic terms. This model operates on a tract level, using percentage of each population group, population density, and would ideally also include variables like unemployment rates, percentage renters, etc.

The predictions shown for each race or ethnicity group are fairly consistent with the results shown above. The distinct separation between the white and Hispanic distributions as compared to the black and 'other' distributions is mirrored in the model predictions. The model appears to follow the observed patterns fairly well, aside from a strange fit for the 'other' distribution in the 5^th^ percentile. 

```{r quantreg, echo = FALSE, fig.height=6}
sample = sample_frac(data, size = 0.10)
sample$p_white = sample$white/sample$pop
sample$p_black = sample$black/sample$pop
sample$p_hispanic = sample$hispanic/sample$pop
sample$p_other = sample$other/sample$pop

test = data.frame(year = rep(seq(1990, 2013), 4), 
                  p_white = c(rep(.85, 24), rep(0.05, 72)), 
                  p_black = c(rep(0.05, 24), rep(0.85, 24), rep(0.05, 48)), 
                  p_hispanic = c(rep(0.05, 48), rep(0.85, 24), rep(0.05, 24)), 
                  p_other =c(rep(0.05, 72), rep(0.85, 24)), 
                  density = rep(10, 96))

plot_quant = function(pred) {
  min = min(pred)
  max = max(pred)
  years = seq(1990, 2013)
  five = ggplot() + geom_line(aes(x = years, pred[1:24, 1], color = "white")) +
  geom_line(aes(x = years, pred[25:48, 1], color = "black")) +
  geom_line(aes(x = years, pred[49:72, 1], color = "hispanic")) +
  geom_line(aes(x = years, pred[73:96, 1], color = "other")) +
  labs(x = "Years", y = "Concentration, 5th Percentile") +
  scale_y_log10(limits = c(min, max), breaks = scales::trans_breaks("log10", function(x) 10^x), 
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(.5,"mm"), mid = unit(2,"mm"),  
                      long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  guides(color = FALSE)
  
  fifty = ggplot() + geom_line(aes(x = years, pred[1:24, 2], color = "white")) +
  geom_line(aes(x = years, pred[25:48, 2], color = "black")) +
  geom_line(aes(x = years, pred[49:72, 2], color = "hispanic")) +
  geom_line(aes(x = years, pred[73:96, 2], color = "other")) +
  labs(x = "Years", y = "Concentration, 50th Percentile") + 
  scale_y_log10(limits = c(min, max), breaks = scales::trans_breaks("log10", function(x) 10^x),
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(.5,"mm"), mid = unit(2,"mm"),  
                      long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  guides(color = FALSE)
  
  ninety = ggplot() + geom_line(aes(x = years, pred[1:24, 3], color = "white")) +
  geom_line(aes(x = years, pred[25:48, 3], color = "black")) +
  geom_line(aes(x = years, pred[49:72, 3], color = "hispanic")) +
  geom_line(aes(x = years, pred[73:96, 3], color = "other")) +
  labs(x = "Years", y = "Concentration, 95th Percentile") +  
  scale_y_log10(limits = c(min, max), breaks = scales::trans_breaks("log10", function(x) 10^x), 
                labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  annotation_logticks(short = unit(.5,"mm"), mid = unit(2,"mm"),  
                      long = unit(3.5,"mm"), sides = "l", color = "gray65") +
  guides(color = FALSE)
  
  grid.arrange(arrangeGrob(five, fifty, ninety, nrow=1), color_legend, nrow=2,heights=c(10, 1))
} 

quant_den = rq(log(concentration)~year+p_white+p_black+p_hispanic+p_other+I(year^3)*(p_white+p_black+p_hispanic+p_other+density)+density*(p_white+p_black+p_hispanic+p_other+density), tau = c(0.05, 0.5, 0.95), data = sample)

plot_quant(exp(predict.rq(quant_den, test)))
```

By adding additional block level data to this regression, we may be able to discuss the magnitude of toxicity differences that are actually attributable to race, and will be informed on the other factors that hold importance in predicting toxicity. Above sections address the empirical reduction in toxicity and the reduction amount attributable to shifts of minority placement in the distribution. An approach able to take it a step further and find the differences attributable to race would add significant value.

<!--chapter:end:06-results.Rmd-->

# Public Interaction {#publicdata}

## Data Accessibility

TRI data originates from The Emergency Planning and Community Right-to-Know Act (EPCRA). The bill was largely motivated by an incident at a chemical production plant in Bhopal, India. Approximately 40 tons of Methyl Isocyanate was released in to the air, killing upwards of 5000 people living in the surrounding area. The disaster created a panic in the United States, and created public demand for transparency on toxic releases in their communities. 

Public use generally doesn't extend to the full depth of TRI data, due to its size and complexity. Simple tools were developed by the EPA to allow public access to the data, including [a map](https://www.epa.gov/rsei/rsei-results-map) that allows you to click on a state and learn what number it is ranked in the US. Data available has incredible potential to allow access to much richer information on a much more local level. There is also [an app](https://www.epa.gov/rsei/get-easyrsei) that allows for investigation of RSEI data. Though quite thorough, it requires extensive setup. 

The intent of this app is to allow an easier outlet to find information about local RSEI data, allow comparisons more complex than rankings, and introduce environmental justice concepts in the context of RSEI data. 

## App Intent and Description

The app built focuses on communicating the distribution of toxicity in a given local area as compared to the national and state distributions. The app was build primarily through Shiny (Chang, 2017). Additionally, it shows the difference in toxicity burden experienced locally by black communities as compared to white communities. 

The priority in organizing the app was to provide as much information as possible in as intuitive a form as possible. To do this, we prioritized three pieces of information we found to be most useful for communities interested in their toxicities: a map of toxicities in surrounding areas, a plot showing the distribution of toxicities within their county, and the distribution of toxicities experienced by black and white groups within their county.

The app functions through a location search. By geolocating the given search address, the relevant data and plots will be shown. 

![](https://raw.githubusercontent.com/DukeStatSci/thesis-sp18-driscoll-envjustice/master/index/figure/north_carolina_shiny.png)

A choropleth map forms the centerpiece of the app, showing the average toxicity of counties in the area surrounding the point. This contextualizes the toxicity, which is unit-less and only interpretable in comparison to other toxicities. Choropleth maps are a familiar form of communicating location based data. 

The second chart plots the distributions of toxicity experienced in the nation, the state, and within the county. This gives some additional context that the map doesn't provide, showing how the state varies from the national distribution, and how the county differs from the state. This might convey interesting information in areas that are especially clean or dirty compared to their state overall. 

The third, and last, chart is meant to convey the environmental justice themes discussed in this project at large. Instead of showing the distributions of toxicity experienced at different geographic levels, this plot shows the distributions of toxicity experienced by the black and white populations of the selected county. 

## Computational Limitations

RSEI's origin lies in corporate accountability, and that may be an area that the public would be interested in accessing data for. Specifically, data on which companies are polluting locally, and which chemicals are being released might be useful. It would be possible to filter toxicity by many metrics, including the facility, and the specific chemical, but it isn't computationally feasible as it would need to reference the 4TB of disaggregated microdata.

Feasibility issues also arise when attempting to use block group and tract data. Visualizing geography at that level is very slow to render, and makes the app too slow to be reasonably useful. Despite that, mapping at a county level still provides significant context to the toxicity measure.

## Further Data Engagement

With the data publicly available, this work is entirely reproducible. To make that a more accessible process I've created a package, ["rseiAnalysis"](www.github.com/amd112/rseiAnalysis), that helps transform the initial disaggregated microdata in to consistent tract level estimates, and combines them with demographic data.

The package contains functions that will aggregate geography, transform data from demographic count to percentile of toxicity for each demographic, create plots of the CDF's for each group, or simulate what distributions would have been given percentile placement stayed the same across time.

<!--chapter:end:07-publicdata.Rmd-->

# Conclusion {#conclusion}

In the literature there is disagreement on the verifiability of environmental racism, with some studies finding extraordinary differences in environments experienced by minorities, others hypothesizing that none were found due to the geographic unit of analysis, and yet others claiming that all toxicity differences can be accounted for by other geographic or economic characteristics - not race. 

The most fundamental criticisms of the field of environmental justice are twofold. Firstly, that due to the prevalence of geographically and temporally focused studies, no results are generalizable, and the field has not shown a true difference in minority and white populations as national groups. In the previously quoted words of one author, all that can be surmised from the field as a whole is "that in some specific areas, some groups in the population may in some instances live closer to some selected environmental hazards." (Anderton et al., 1994) I attempt to address this by using data spanning the entire nation, over an unusually long period of time. This data, by definition, can be thought of as representative of minority and white populations as national groups, and differences cannot be attributed to random change in a temporal snapshot of data. 

The second large criticism of the field is that racial differences in experienced environmental hazard are manufactured. Rather than reflecting a 'true difference' in experiences by race, it's stated that positive results can only be attributed to a reflection of "known economic inequities in residential patterns around existing industrial centers" (Szasz and Meuser, 1997), effectively concluding that these inequalities are a class issue - not a race issue. While inequities we see are not necessarily related to "prejudicial choice[s]" in siting of new facilities, there is a disparity in experiences, regardless of intent or cause. 

The data I have presented appears to tangibly show a difference in the distributions of toxicity experienced by minority groups. The strength of this analysis relies on the length of RSEI data available, which has yet to be examined over such a long period. The longest temporal period examined spanned the years of 1970 to 1995, as conducted by Been and Gupta. The longest recent study of toxicity using RSEI data covered the years of 1995 to 2004, 15 fewer years than the currently presented data. The broad scope of this work allows statements that cover the entire population over a lengthy period, but limitations in data don't allow for statements covering all toxicity, only that consistently measured by the TRI program. Additionally, no inferences can be made on the impact this toxicity has, in terms of health or impact on lifestyle. 

# Future Work

This work has yet to include geographic variables (such as census region, population density, suburb vs. city, level of manufacturing, availability of jobs, housing market, access to transportation etc.), which may add to both the explanatory and predictive power of this analysis. 

Potential areas for improvement include using more detailed income data, using small area estimation to generate cross tabulations at lower geographic levels, and creating models with more local data in order to investigate what portion of the difference is attributable to race. Currently presented results may be useful as a baseline on the current trends in environmental inequality at a national scale, and as a more interpretable individual level description of the experiences of various racial and ethnic groups.

Data availability is very limited in this work, as the app only provides access to a very small set of data points. Though residents would likely be most interested in how their toxicity compares to those around them, they might also want more detailed data on what companies and chemicals are most common in their area. Unfortunately, hosting that much data in the Shiny app isn't feasible. 

<!--chapter:end:08-conclusion.Rmd-->

